\documentclass[12pt, letterpaper]{article}

\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage[left=0.6in, right=0.6in, top=1in, bottom=1in]{geometry}

% for code snippets
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0.5,0.65,0.5}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{code_blue}{rgb}{0.10,0.27,0.92}
\definecolor{str_red}{rgb}{0.87,0.2,0.14}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{code_blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{str_red},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\title{CSE 101 Homework 6}
\author{Brian Masse, Kreshiv Chawla, Taira Sakamoto, Emily Xie, Annabelle Coles}
\date{November 25, 2025}

\begin{document}

\maketitle
\newpage

\begin{enumerate}

% MARK: Question 1
\newpage
\item \textbf{Recurrence Relations}

\begin{enumerate}
\item $T(n) = 4T(\lfloor n/4 \rfloor) + cn^3, n \ge 2,    T(1) = c$

The master theorem applies.

\begin{eqnarray*}
    T(n) &=& 4T(\lfloor n/4 \rfloor) + cn^3 \\
    &\in& 4T(n/4) + O(n^3)
\end{eqnarray*}

$a = 4, b = 4, d = 3 \implies a < b^d \implies T(n) \in O(n^3)$

\-\
\item $T(n) = 2*T(n-3 )$ for $n \ge 4$, $T(1)=c$

The master theorem does not apply.
\begin{flalign*}
    &1: 2T(n-3) \\
    &2: 2\cdot 2T(n-6)& \\
    \vdots
    &k: 2^k \cdot T(n - 3k)&
\end{flalign*}

Solving for the value of k that yields $T(1):$
$n - 3k = 1 \implies k = 1/3(n - 1)$. Thus,
\[ T(n) = c \cdot 2 ^ {1/3(n - 1)} \in O(2^{n/3})\]

\-\
\item $T(n) =  T(\lfloor n/4 \rfloor) + c,  T(1) = c$

The master theorem applies.

\begin{eqnarray*}
    T(n) &=& T(\lfloor n/4 \rfloor) + C \\
    &\in& T( n / 4) + O(1)
\end{eqnarray*}

$a = 1, b = 4, d = 0 \implies a = b^d \implies T(n) \in O(n^d \cdot logn) = O(logn)$

\-\
\item $T(n) = (\log n) T(\lfloor n/2 \rfloor ), n \ge 2; T(1)=c$.
The master theorem does not apply. The master theorem requires a recurrence of the form aT(n/b) + f(n) where a and b are constants and a = (log n) depends on n.

\begin{flalign*}
&1: (\log n),T(n/2) &\
&2: (\log n),(\log (n/2)),T(n/4) &\
&3: (\log n),(\log (n/2)),(\log (n/4)),T(n/8) &\
&\vdots &\
&k: \displaystyle\left(\prod_{i=0}^{k-1}\log!\left(\frac{n}{2^i}\right)\right);T!\left(\frac{n}{2^k}\right) &
\end{flalign*}

Solving for the value of k that yields $T(1):$
$n/(2^k) = 1 \implies k = \log_2(n)$. Thus,
\[ T(n) = c \cdot (log_2(n))! \in O(2^{n/3})\]
\end{enumerate}

% MARK: Question 2
\newpage
\item \textbf{High Frequency Element}


Say we have an array of numbers $A[1...n]$.  $x$ is {\em high frequency } in $A$ if it occurs more than $ n/2 $ times in $A$, i.e., there are strictly more than $n/2$ many indices $1 \le i \le n$ with $A[i]=x$.  Here's an algorithm that finds a high frequency element if one exists (it may return an element if no high frequency element exists):

\par
HF(A[1..n])
\begin{enumerate}
\item If $n=0$ return ``No HF element''. 
\item If $n=1$ return $A[1]$.
\item If $n$ is odd do:
\item ~~~~$Count=0$
\item ~~~~FOR $I=1$ to $n$ IF $A[I]=A[n]$ THEN $Count++$
\item ~~~~IF $Count > n/2$ THEN Return $A[n]$
\item Initialize an array $B[1.. \lfloor n/2 \rfloor]$.
\item $I=1, J=1$.
\item While $I < n$ do: 
\item ~~~IF $A[I]==A[I+1]$ THEN $B[J]=A[I], J++$
\item ~~~$I=I+2$.
\item Return $HF(B[1..J-1])$.
\end{enumerate}

% MARK: Q2.a
Questions:
\begin{enumerate}
\item Give the recursive calls the algorithm would make on input $A[1..7] = (1,4, 3,3, 2,3, 3)$.

Call 1:
\begin{itemize}
    \item Arr = $[1, 4, 3, 3, 2, 3, 3]$
    \item n = $7$
    \item count = $4$
\end{itemize}

$4 > floor(7 / 2) = 3 \implies return 3;$

\-\
% MARK: Q2.b
\item Prove that if $x$ is a high-frequency element in $A[1..n]$, then
$x$ is a high frequency element in $B[1...J-1]$ at the end of the loop.

The only way to reach $J++$ is to have a consecutive pair in A. 

There must be at least 1 pair $(x,x) \in A$:
    \begin {itemize}
        \item If n is even: 
        
        the number of times x appears in a, $|x| >  \lfloor{n / 2}\rfloor = n / 2$. Thus you cannot put a $y \ne x$ between every x, and thus there is a consecutive pair $(x,x)$

        \-\
        \item If n is odd:
        
        If there is a space between every occurrence of x, then $A[1] = x = A[n]$, which would have been detected in the count section of the algorithm and returned. 

        \-\ \newline
        Otherwise ($A[n] \ne x$), you cannot space apart $\lfloor{n/2}\rfloor + 1 $ xs in $\frac{n - 1}{1}$ spaces
        \-\ 

    \end {itemize}

Therefore B will always have at least 1 x in it. The only other way to add an element to B is if there is another consecutive pair, $(y,y)$ such that $y \ne x$. However, for any $(y,y)$ there exists at least another $(x,x)$

Consider placing the required $(x,x)$ at the beginning of A:
    \begin {itemize}
        \item Place a $(y,y)$. There are now $n - 4$ remaining spots
        \item For x to be a highest frequency item, you must place $\ge n/2 - 1$ more xs. 
        \item $\frac{n-4}{2} = \frac{n}{2} - 2 < n/2 - 1$
    \end {itemize}

Thus, you must fill more than half of the remaining spots with x, meaning that there must be another consecutive pair of xs. Therefore, for every added $y$ in B, there is another $x$ in B. So at most $A \ni | (x,x)| > |(y,y)| \implies B \ni |x| > |y|$

Therefore x is the highest frequency in B as well. 

\-\
% MARK: Question 2.c
\item Use this to prove that if $x$ is a high-frequency element in $A[1..n]$, then $HF(A[1..n])=x$.

Note that every recursive call has a smaller B: $|B_{i+1}| \le 1/2|B_i|$. Thus B is always decreasing, and by the previous question, x is always the highest frequency item in B. During each iteration there are several possibilities:
    \begin {itemize}
        \item $|B_i|$ is odd and $B.last() = x$:
        
        return x.

        \emph{This cannot return any other value other than x, since no other value appears over half the time (by problem statement)}

        \-\
        \item $|B_i|$ is even or $B.last() \ne x$
        
        Iterate to the next $B_{i+1}$. By the previous question, if x is the highest frequency item in $B_i$, then $B_{i+1}$ must have at least 1 item, namely $x$. 

    \end {itemize}

Thus after each recursive call, B must get smaller, can never be empty, and must contain x. The only value the function is able to return is x, which happens in the smallest (end) case, of $B = \{x\}$

\-\
% MARK: Question 2.d
\item Give a worst-case time analysis for this algorithm.

The time analysis can be solved via the master theorem. First, each call only takes $O(n)$ time, since, at worst, it loops through every element twice (once for cunt, and the second to construct B.). Then:
    \begin {itemize}
        \item Each iteration only spawns 1 sub problem
        \item Each subproblem is, at worst $n/2$.
        
        This happens when the array only has consecutive pairs, and thus adds an element to B.
    \end {itemize}

Thus,

\[ T(n) = 1 \cdot T( n / 2) + O(n)\]

By the master theorem: $a = 1, b = 2, d = 1 \implies a < b^d \implies T(n) \in O(n)$

\end{enumerate}

% MARK: Question 3
\newpage
\item \textbf{Weighted Median}


Say that we are given a list of pairs of values and weights, with weights greater than $0$, $(v_1,w_1),..(v_n,w_n)$.
Let $W= \sum_{1 \le i \le n} w_i$ be the total weight. The weighted median is a value $v_j$ with $\sum_{1 \le i \le n, v_i < v_j} w_i \le W/2$ and  $\sum_{1 \le i \le n, v_i > v_j} w_i \le W/2$.


For example, if the list had elements $(2,.1), (4,.2), (-3, .2),(1,.4), (5,.1)$,we can compute $W=1$, so $W/2=.5$.  A weighted median is $1$, because the sum of the weights of values less than $1$ is $.2$ and the sum of the weights larger than $1$ is $.1+.2+.1= .4$.

Give an efficient algorithm (faster than sorting the list) to compute a weighted
median. 

% MARK: Q3.a
\-\ \newline 
\begin{lstlisting}
// pass in the list of pairs, the size of the list, and half the total weight
// The final piece can be precomputed in linear time. 
weighted_median(list L, size n, WM):

    // Find the median of the given list (by value, not weight)
    // Using the select algorithm from class
    median = select_lowest(L, n / 2)

    // create 3 sub array for pairs with a value <, =, > the median
    // keep track of their cumulative weight
    SL = []; WL = 0;
    SM = []
    SR = []; WR = 0;

    // loop through the list to build sub arrays.
    for pair in L:
        if pair.value < median.value:
            SL.add(pair)
            WL += pair.weight
        elif pair.value > median.value:
            SR.add(pair)
            WR += pair.weight
        else:
            SM.add(pair)

    // if both sides are less than the target weight, that value is the weighted median
    if (WL < WM && WR < WM):
        return median

    // run the algorithm recursively on whichever subset was greater than the target weight
    if (WL > WM):
        return weighted_median(WL, WL.size(), WM)
    else:
        return weighted_median(WR, WR.size(), WM)
\end{lstlisting}

% MARK: Q3.b
\emph{Short Correctness Proof}

The algorithm recursively calls the select median algorithm discussed in class. It is assumed that, for any set, it correctly returns the median. Once the median is found, the algorithm uses it as a pivot to create 3 partitions: values less than the median, equal to the median, and greater than the median, and calculates the total weight of each partition. 

There are 2 outcomes:

\begin{itemize}
    \item  The weight of both subsets are less than $W/2$. This implies the median is the weighted median and returns
    \item The weight of one of the subsets is greater than $W/2$. In this case, the weighted median must be in the heavier subset, since being in either other subset implies values above or below it sum above $W/2$, violating the definition of the weighted median. Thus, the algorithm runs itself on the smaller subset. 
    
    \-\ \newline
    \emph{Note: Only 1 subset can have a weight $> W/2$, since all others must have weight $w < W/2$ to all sum to $W$}

    \emph{Note: A recursive call will never contain an empty set. If there are no numbers above or below the median returned by select, that number is the weighted median.}
\end{itemize}

% MARK: Q3.c
\emph {Analysis / Efficiency}

This algorithm can be determined using the master theorem. First note:

\begin{itemize}
    \item Calculating target weight $\in O(n)$
    \item Select (from class) $\in O(n \cdot log(n))$
    \item partitioning into subsets $\in O(n)$
    \item The partitions will always be roughly $n/2$ elements large, since they use the median as the pivot, which by definition is in the center of the set.
\end{itemize}

Together this implies the total time complexity, $T(n):$
\[ T(n) = 1 \cdot T( n / 2) + O(n \cdot log(n)) \]

\begin{enumerate}
    \item Only 1 subset is recursively called on $\implies$ 1 subroutine
    \item With median as input, subroutines are roughly $n / 2$
    \item The total time complexity of each call is dominated by the select median $\implies \in O(n \cdot logn)$
\end{enumerate}

By the master theorem:

\begin{eqnarray*}
    f(n) &=& n \cdot log(n) \\
    &\in& \Omega(n^{log_b(a)}) = \Omega(1) \\
    &\implies& T(n) \in O(f(n))
\end{eqnarray*}

Thus, the total runtime complexity is $O(n\cdot logn)$




% MARK: Question 4
\newpage
\item \textbf{Weighted Independent Set for Trees}

A subset $S$ of vertices in an undirected graph is an {\em independent
set} if it doesn't contain both ends of any edge.  If we assign every vertex a weight $w(x) >0$ , the {\em maximum weight independent set} is to find the independent set of the graph that has maximum possible
total weight of its vertices.  While the maximum weight independent set problem is $NP$-hard, some special cases can be solved efficiently. In particular, consider the special case when the underlying graph is a complete binary tree of depth $k$, so $|V|=2^{k+1}-1$.  Give a divide-and-conquer algorithm for
this problem that runs in polynomial time. (5 points clear algorithm description, 5 points for short correctness argument, 5 points for correct time analysis, and 5 points for efficiency; the best algorithm is $O(|V|)$ time.)

% MARK: Q4.a
\begin{lstlisting}
// pass in the starting node. In the specialized problem, this will always be the root. 
// The function returns 2 things:
//   1. The highest weight independent set with the root
//   2. The highest weight independent set without the root
// The answer is the set with the larger weight at the end. 
def WeightedSets(node):

    if node has no children:
        return ( [node], [] )

    if node has 1 child:
        return ( [node], [child] )
    
    left_result = WeightedSets(leftChild)
    right_result = WeightedSets(rightChild)

    with_left = left_result[0]; without_left = left_result[1]
    with_right = right_result[0]; without_right = right_result[1]

    with_node = [], without_node = []

    // Generate the optimal set containing the current node
    with_node += without_left + without_right + node

    // generate the optimal set without the current node
    if weight(with_right) > weight(without_right):
        without_node += with_right
    else:
        without_node += without_right
    if weight(with_left) > weight(without_left):
        without_node += with_left
    else:
        without_node += without_left
    
    return with_node, without_node

// calculate the actual maxiumum independent set
result = WeightedSets(root)
max_set = max(weight(result[0]), weight(result[1]))

\end{lstlisting}

% MARK: Q4.b
\emph{Short Correctness Proof}

This algorithm can be proved via induction on the size on the input. 

Base Case:
\begin{itemize}
    \item n = 1. 
    
    There is only one node. The algorithm returns a set containing the node and an empty set. The non-empty set is trivially the max independent set.

    \item n = 2
    
    There are 2 nodes, 1 with 1 child. The algorithm returns 2 sets each with one of the nodes. The set with the bigger weight is trivially the max independent set.
\end{itemize}

Induction step:

Assume that for any tree of size $n - 1, n > 2$ the algorithm returns the largest sets with and without the root node. Then for an input of size n:

\begin{itemize}
    \item Returning the largest set with the node
    
    In this case, it is not possible to include either of the node's children, since that would complete the edge. Given that all weights are positive, the largest weight this set could have is te union of $without\_left$ and $without\_right$

    \item Returning the largest set without the node
    
    In this case, it is possible to include or not include either of the node's children. Thus the answer will be the union of the biggest set on the left (with or without the left child), and the biggest set on the right (with or without the right child)

\end{itemize}

Thus for an input of size n, the function returns the largest set for both cases, and thus the largest independent set. 

% MARK: Q4.c
\-\ \newline
\emph{Time Analysis / Efficiency}

The time complexity of this problem can be solved via the master theorem. Note:

\begin {itemize}
    \item The runtime of each subroutine is $O(1)$. 
    
    \-\ \newline
    \emph{ Note: It may be more than O(1) to find the weight of a set. However, it is trivially easy modify the algorithm to build up and return the weight of the 2 sets with each function call to avoid having to compute the weight from the set itself. }

    \-\
    \item Each call generates, at most, 2 sub problems.
    \item Each sub problem is roughly $n/2$ big.
\end {itemize}

This implies that total runtime, $T(n)$ is:
\[T(n) = 2 \cdot T(n / 2) + O(1)\]

By the master theorem: $2 = a > b^d = 2^0 = 1 \implies T(n) \in O(n ^ {log_b(a)}) = O(n^1) = O(n) = O(|V|)$

% MARK: Question 5
\newpage
\item \textbf{Karatsuba implementation}

This problem is designed to teach you an idea that makes divide-and-conquer algorithms that only improve time for huge inputs into ones that give substantial improvements even for moderate sized inputs.

Implement both the Karatsuba method for multiplying polynomials from the ungraded problems above and
a straight-forward $O(n^2)$ polynomial multiplication algorithm.  Collect
average running times for a wide range of input sizes $n$, say powers of $2$ until the algorithm is
taking over 15 minutes to run,  for random polynomials with co-efficients
$0$ or $1$.   Graph these on a log-log scale, log n vs. log (algorithm time).  
How big are inputs where the Karatsuba method is faster, or how big would
you interpolate such inputs to be from your data (if there are no actual
data points where Karatsuba is better)?   Then try a hybrid algorithm,
where we use the Karatusba recursion when $n > T$ and the quadratic time
method in recursive calls when $n \leq T$.  For a wide range of possible
$T$'s, starting with rather small values such as $T=16$, graph the hybrid's
performance and compare to the other two.  What do you conclude from this
experiment?  

(2 points clearly describing features of implementation and experiment, 
such as PL, libraries, type of computer, etc.  For each of Karatsuba,
quadratic algorithm and hybrid, 2 points for running experiment with
adequate variety of input sizes and 2 points
for clearly presenting results. 6 points for conclusions 
based on comparing results.)




\end{enumerate}
\end{document}

